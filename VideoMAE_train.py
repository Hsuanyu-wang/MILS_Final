# ============================================================================
# VideoMAE é¢¨éšªé æ¸¬å®Œæ•´å¯¦ä½œ
# ============================================================================

import os
import cv2
import torch
import pandas as pd
import numpy as np
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from transformers import AutoImageProcessor, VideoMAEForVideoClassification
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# å®‰è£å¿…è¦å¥—ä»¶
# !pip install transformers torch torchvision opencv-python pandas numpy pillow scikit-learn matplotlib

class RiskVideoDataset(Dataset):
    """VideoMAE é¢¨éšªé æ¸¬è³‡æ–™é›†"""
    
    def __init__(self, csv_file, root_dir, image_processor, sample_num=16, is_train=True):
        """
        Args:
            csv_file: CSVæª”æ¡ˆè·¯å¾‘ (æ ¼å¼: file_name,risk)
            root_dir: å½±åƒè³‡æ–™å¤¾è·¯å¾‘
            image_processor: VideoMAEçš„å½±åƒè™•ç†å™¨
            sample_num: æ¯å€‹å½±ç‰‡æ¡æ¨£çš„å¹€æ•¸
            is_train: æ˜¯å¦ç‚ºè¨“ç·´æ¨¡å¼
        """
        self.data = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.image_processor = image_processor
        self.sample_num = sample_num
        self.is_train = is_train
        
        print(f"è¼‰å…¥è³‡æ–™é›†: {len(self.data)} å€‹æ¨£æœ¬")
        print(f"Riskåˆ†å¸ƒ: {self.data['risk'].value_counts().to_dict()}")
    
    def load_video_frames(self, video_folder):
        """è¼‰å…¥å½±ç‰‡å¹€åºåˆ—"""
        frames = []
        video_path = os.path.join(self.root_dir, video_folder)
        
        if not os.path.exists(video_path):
            print(f"è­¦å‘Š: æ‰¾ä¸åˆ°è³‡æ–™å¤¾ {video_path}")
            return [Image.new('RGB', (224, 224), color='black')] * self.sample_num
        
        # è¼‰å…¥è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰å½±åƒ
        image_files = sorted([f for f in os.listdir(video_path) 
                            if f.lower().endswith(('.jpg', '.png', '.jpeg'))])
        
        if len(image_files) == 0:
            print(f"è­¦å‘Š: è³‡æ–™å¤¾ä¸­æ²’æœ‰å½±åƒæª”æ¡ˆ {video_path}")
            return [Image.new('RGB', (224, 224), color='black')] * self.sample_num
        
        # è¼‰å…¥æ‰€æœ‰å½±åƒ
        for img_file in image_files:
            img_path = os.path.join(video_path, img_file)
            try:
                image = Image.open(img_path).convert('RGB')
                frames.append(image)
            except Exception as e:
                print(f"ç„¡æ³•è¼‰å…¥å½±åƒ {img_path}: {e}")
                continue
        
        # å¦‚æœå½±åƒæ•¸é‡è¶…ésample_numï¼Œé€²è¡Œå‡å‹»æ¡æ¨£
        if len(frames) > self.sample_num:
            indices = np.linspace(0, len(frames) - 1, self.sample_num).astype(int)
            frames = [frames[i] for i in indices]
        
        # å¦‚æœå½±åƒæ•¸é‡ä¸è¶³ï¼Œé‡è¤‡æœ€å¾Œä¸€å¹€
        while len(frames) < self.sample_num:
            if frames:
                frames.append(frames[-1])
            else:
                frames.append(Image.new('RGB', (224, 224), color='black'))
        
        return frames[:self.sample_num]
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        row = self.data.iloc[idx]
        file_name = row['file_name']  # ä¾‹å¦‚: freeway_0000
        risk_label = int(row['risk'])  # 0=safe, 1=risk
        
        try:
            # è¼‰å…¥å½±ç‰‡å¹€
            frames = self.load_video_frames(file_name)
            
            # ä½¿ç”¨VideoMAEçš„å½±åƒè™•ç†å™¨
            inputs = self.image_processor(frames, return_tensors="pt")
            
            return {
                'pixel_values': inputs['pixel_values'].squeeze(0),
                'labels': torch.tensor(risk_label, dtype=torch.long),
                'file_name': file_name
            }
        except Exception as e:
            print(f"è™•ç† {file_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # è¿”å›ç©ºç™½è³‡æ–™
            blank_frames = [Image.new('RGB', (224, 224), color='black')] * self.sample_num
            inputs = self.image_processor(blank_frames, return_tensors="pt")
            return {
                'pixel_values': inputs['pixel_values'].squeeze(0),
                'labels': torch.tensor(risk_label, dtype=torch.long),
                'file_name': file_name
            }

class VideoMAERiskPredictor:
    """VideoMAE é¢¨éšªé æ¸¬å™¨"""
    
    def __init__(self, model_name="MCG-NJU/videomae-base-finetuned-kinetics"):
        self.model_name = model_name
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.image_processor = None
        self.model = None
        
    def create_model(self):
        """å»ºç«‹æ¨¡å‹"""
        self.image_processor = AutoImageProcessor.from_pretrained(self.model_name)
        self.model = VideoMAEForVideoClassification.from_pretrained(
            self.model_name,
            num_labels=2,  # äºŒå…ƒåˆ†é¡ï¼š0=safe, 1=risk
            ignore_mismatched_sizes=True
        )
        self.model.to(self.device)
        return self.model, self.image_processor
    
    def create_datasets(self, train_csv, test_csv, train_dir, test_dir):
        """å»ºç«‹è¨“ç·´å’Œæ¸¬è©¦è³‡æ–™é›†"""
        if self.image_processor is None:
            self.create_model()
            
        train_dataset = RiskVideoDataset(
            csv_file=train_csv,
            root_dir=train_dir,
            image_processor=self.image_processor,
            is_train=True
        )
        
        test_dataset = RiskVideoDataset(
            csv_file=test_csv,
            root_dir=test_dir,
            image_processor=self.image_processor,
            is_train=False
        )
        
        return train_dataset, test_dataset
    
    def create_dataloaders(self, train_dataset, test_dataset, batch_size=2):
        """å»ºç«‹è³‡æ–™è¼‰å…¥å™¨"""
        train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size,
            shuffle=True,
            num_workers=2,
            pin_memory=True
        )
        
        test_loader = DataLoader(
            test_dataset, 
            batch_size=batch_size, 
            shuffle=False,
            num_workers=2,
            pin_memory=True
        )
        
        return train_loader, test_loader
    
    def train(self, train_loader, test_loader, epochs=15, learning_rate=5e-5, save_path='videomae_risk_model.pth'):
        """è¨“ç·´æ¨¡å‹"""
        if self.model is None:
            raise ValueError("è«‹å…ˆå»ºç«‹æ¨¡å‹")
            
        print(f"é–‹å§‹è¨“ç·´ï¼Œä½¿ç”¨è¨­å‚™: {self.device}")
        
        # å„ªåŒ–å™¨å’Œèª¿åº¦å™¨
        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=0.01)
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
        
        # è¨˜éŒ„è¨“ç·´éç¨‹
        train_losses = []
        val_accuracies = []
        best_accuracy = 0.0
        
        for epoch in range(epochs):
            # è¨“ç·´éšæ®µ
            self.model.train()
            total_loss = 0
            train_correct = 0
            train_total = 0
            
            print(f"\nEpoch {epoch+1}/{epochs}")
            print("-" * 60)
            
            for batch_idx, batch in enumerate(train_loader):
                try:
                    pixel_values = batch['pixel_values'].to(self.device)
                    labels = batch['labels'].to(self.device)
                    
                    optimizer.zero_grad()
                    
                    # å‰å‘å‚³æ’­
                    outputs = self.model(pixel_values=pixel_values, labels=labels)
                    loss = outputs.loss
                    
                    # åå‘å‚³æ’­
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                    optimizer.step()
                    
                    total_loss += loss.item()
                    
                    # è¨ˆç®—è¨“ç·´æº–ç¢ºç‡
                    predictions = torch.argmax(outputs.logits, dim=1)
                    train_total += labels.size(0)
                    train_correct += (predictions == labels).sum().item()
                    
                    if (batch_idx + 1) % 10 == 0:
                        print(f"  Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}")
                        
                except Exception as e:
                    print(f"  è¨“ç·´æ‰¹æ¬¡ {batch_idx} ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            avg_train_loss = total_loss / len(train_loader)
            train_accuracy = train_correct / train_total if train_total > 0 else 0
            train_losses.append(avg_train_loss)
            
            # é©—è­‰éšæ®µ
            val_accuracy, val_report = self.evaluate(test_loader)
            val_accuracies.append(val_accuracy)
            
            # å­¸ç¿’ç‡èª¿åº¦
            scheduler.step()
            
            print(f"è¨“ç·´æå¤±: {avg_train_loss:.4f}")
            print(f"è¨“ç·´æº–ç¢ºç‡: {train_accuracy:.4f}")
            print(f"é©—è­‰æº–ç¢ºç‡: {val_accuracy:.4f}")
            print(f"å­¸ç¿’ç‡: {optimizer.param_groups[0]['lr']:.6f}")
            
            # å„²å­˜æœ€ä½³æ¨¡å‹
            if val_accuracy > best_accuracy:
                best_accuracy = val_accuracy
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'best_accuracy': best_accuracy,
                    'image_processor': self.image_processor,
                }, save_path)
                print(f"  âœ“ å„²å­˜æœ€ä½³æ¨¡å‹ï¼Œæº–ç¢ºç‡: {best_accuracy:.4f}")
        
        print(f"\nğŸ‰ è¨“ç·´å®Œæˆï¼æœ€ä½³é©—è­‰æº–ç¢ºç‡: {best_accuracy:.4f}")
        return train_losses, val_accuracies
    
    def evaluate(self, test_loader):
        """è©•ä¼°æ¨¡å‹"""
        self.model.eval()
        correct = 0
        total = 0
        all_predictions = []
        all_labels = []
        
        with torch.no_grad():
            for batch in test_loader:
                try:
                    pixel_values = batch['pixel_values'].to(self.device)
                    labels = batch['labels'].to(self.device)
                    
                    outputs = self.model(pixel_values=pixel_values)
                    predictions = torch.argmax(outputs.logits, dim=1)
                    
                    total += labels.size(0)
                    correct += (predictions == labels).sum().item()
                    
                    all_predictions.extend(predictions.cpu().numpy())
                    all_labels.extend(labels.cpu().numpy())
                    
                except Exception as e:
                    print(f"è©•ä¼°æ‰¹æ¬¡ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
        
        accuracy = correct / total if total > 0 else 0
        
        # ç”Ÿæˆåˆ†é¡å ±å‘Š
        if len(all_predictions) > 0:
            report = classification_report(
                all_labels, all_predictions, 
                target_names=['Safe', 'Risk'],
                output_dict=True
            )
        else:
            report = {}
        
        return accuracy, report
    
    def predict_single_video(self, video_folder, model_path=None):
        """é æ¸¬å–®å€‹å½±ç‰‡çš„é¢¨éšª"""
        if model_path:
            self.load_model(model_path)
        
        if self.model is None or self.image_processor is None:
            raise ValueError("è«‹å…ˆè¼‰å…¥æ¨¡å‹")
        
        self.model.eval()
        
        # å»ºç«‹è‡¨æ™‚è³‡æ–™é›†
        temp_data = pd.DataFrame({'file_name': [os.path.basename(video_folder)], 'risk': [0]})
        temp_csv = 'temp_predict.csv'
        temp_data.to_csv(temp_csv, index=False)
        
        try:
            dataset = RiskVideoDataset(
                csv_file=temp_csv,
                root_dir=os.path.dirname(video_folder),
                image_processor=self.image_processor,
                is_train=False
            )
            
            # ç²å–è³‡æ–™
            data = dataset[0]
            pixel_values = data['pixel_values'].unsqueeze(0).to(self.device)
            
            # é æ¸¬
            with torch.no_grad():
                outputs = self.model(pixel_values=pixel_values)
                probabilities = torch.softmax(outputs.logits, dim=1)
                prediction = torch.argmax(outputs.logits, dim=1)
            
            risk_prob = probabilities[0][1].item()
            safe_prob = probabilities[0][0].item()
            is_risky = prediction[0].item()
            
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if os.path.exists(temp_csv):
                os.remove(temp_csv)
            
            return {
                'prediction': 'Risk' if is_risky else 'Safe',
                'risk_probability': risk_prob,
                'safe_probability': safe_prob,
                'confidence': max(risk_prob, safe_prob)
            }
            
        except Exception as e:
            if os.path.exists(temp_csv):
                os.remove(temp_csv)
            raise e
    
    def load_model(self, model_path):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        checkpoint = torch.load(model_path, map_location=self.device)
        
        if self.model is None:
            self.create_model()
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        print(f"è¼‰å…¥æ¨¡å‹ï¼Œæœ€ä½³æº–ç¢ºç‡: {checkpoint.get('best_accuracy', 'N/A')}")

# ä½¿ç”¨ç¯„ä¾‹
def run_videomae_pipeline():
    """åŸ·è¡ŒVideoMAEå®Œæ•´pipeline"""
    
    # åˆå§‹åŒ–é æ¸¬å™¨
    predictor = VideoMAERiskPredictor()
    
    # å»ºç«‹æ¨¡å‹
    model, image_processor = predictor.create_model()
    
    # è¨­å®šè³‡æ–™è·¯å¾‘ï¼ˆè«‹æ ¹æ“šæ‚¨çš„å¯¦éš›è·¯å¾‘ä¿®æ”¹ï¼‰
    train_csv = 'freeway_train.csv'  # æ‚¨çš„è¨“ç·´CSV
    test_csv = 'freeway_test.csv'    # æ‚¨çš„æ¸¬è©¦CSV  
    train_dir = 'freeway/train'      # è¨“ç·´å½±åƒè³‡æ–™å¤¾
    test_dir = 'freeway/test'        # æ¸¬è©¦å½±åƒè³‡æ–™å¤¾
    
    # å»ºç«‹è³‡æ–™é›†
    train_dataset, test_dataset = predictor.create_datasets(
        train_csv, test_csv, train_dir, test_dir
    )
    
    # å»ºç«‹è³‡æ–™è¼‰å…¥å™¨
    train_loader, test_loader = predictor.create_dataloaders(
        train_dataset, test_dataset, batch_size=2
    )
    
    # è¨“ç·´æ¨¡å‹
    train_losses, val_accuracies = predictor.train(
        train_loader, test_loader, 
        epochs=15, 
        save_path='videomae_freeway_risk.pth'
    )
    
    # æœ€çµ‚è©•ä¼°
    final_accuracy, final_report = predictor.evaluate(test_loader)
    print(f"\næœ€çµ‚æ¸¬è©¦æº–ç¢ºç‡: {final_accuracy:.4f}")
    
    # é æ¸¬å–®å€‹å½±ç‰‡ç¯„ä¾‹
    # result = predictor.predict_single_video('path/to/video/folder')
    # print(f"é æ¸¬çµæœ: {result}")
    
    return predictor, train_losses, val_accuracies

# åŸ·è¡ŒVideoMAE pipeline
if __name__ == "__main__":
    predictor, losses, accuracies = run_videomae_pipeline()
